# ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection

////////////////////////IEEE-CIS Fraud Detection//////////////////////// 
კონკურსი მიზნად ისახავდა გამოგვეცნო თაღლითური ტრანზაქციები. მონაწილეებს ეძლევათ რეალური სამყაროდან აღებული ფართომასშტაბიანი მონაცემთა ნაკრები, 2 data-ად , რომლებიც მოწოდებულია Vesta Corporation-ის მიერ. მონაცემები შეიცავდა ტრანზაქციების შესახებ სხვადასხვა ინფორმაციას, მაგრამ ეს ინფორმაცია დაშიფრულია ამიტომ , რთული იყო წინასწარ გამოგვეცნო რომელი სვეტები იქნებოდა მნიშვნელოვანი და რომლები არა. ასევე მათი შესწავლისას გამოჩნდა , რომ data  იყო დაუბლანსებელი, მის მხოლოდ 3.5 % ს შეადგენდა Fraud-ს და გვქონდა დიდი რაოდენობით null მნიშვნელობები. საბოლოოდ ჩემი მთავარი მიზანი იყო მონაცემების სწორად დამუშავება , დაბალანსება და რაიმე ნიმუშის დაჭერა რათა სწორად გამომეცნო სამიზნე. გამოვიყენე ხის მოდელები , რადგან ისინი კარგად ამუშავებენ დიდ მონაცემებს , რომლებსაც გააჩნია ისეთი პრობლემები როგორიცა დაუბალანსება , დიდი რაოდენობით null-ები , კატეგორული ცვლადები, არაწრფივი კავშირი feature-ებს შორის და ა.შ.

/////////////რეპოზიტორში არსებული ფაილები/////////////

model_experiment_{მოდელის არქიტექტურა}.ipynb

ამ ფაილში თითოეულ ნაბიჯზე ნაცადი მიდგომების კოდები არის დაკომიტებული.Cleaning, Feature Engineering, Feature Selection და Trainin ნაბიჯებით (გამოყოფილი კომენტარებით)

model_inference.ipynb

ამ ფაილში კი მაქვს საბოლოოდ შერჩეული მოდელის დალოუდებისა , SalePrice-ის დაფრედიქთების და სადაბმითების კოდი

/////////////Feature Engineering/////////////

პირველ რიგში, რადგან მონაცემები ორ სეტად მოგვწეოდებოდა რომლებსაც საერთი TransactionID სვეტი ქონდა, ლოგიკურად ჩავთვალე მათი გაერთიანება სწორედ ამ სვეტით.

მეორე რიგში შევისწავლე target-ი, მისი განაწილება და როგორც ზემოთ ვახსენე ვნახე თუ როგორი დაუბალანსებული იყო. მხოლოდ 3.5% იყო fraud.
ამ პრობლემის გამოსწორება კი შეიძლებოდა undersampling-ით , oversampling-ით ან წონების გამოყენებით. 
ჩემს ექსპერიმენტებში გამოყენებული მაქვს მხოლოდ undersampling და წონები. კარგი იქნებოდა თუ გამოვიყენებდით ასევე oversampling , რადგან ამ მიდგომისას undersampling-სგან განსხვავებით არ ხდება მონაცემების დაკარგვა.
ასევე ავღნიშნავ იმას , რომ საუკეთესო მოდელის შემთხვევაში undersampling-მა ძალიან მცირედით მაგრამ მაინც უკეთესი შედეგი აჩვენა ვიდერე წონებმა.

კატეგორული ცვლადების დამუშავებისთვის გამოვიყენე ორი მიდგომა პირველი Label Encoding , რომელიც შედარებით მარტივი ლოგიკისა და დიდი მინაცემებისთვის შედარებით უფრო სწრაფი
და მეორე სემინარზე განხილული WOE და OHE Encoding , რომლების ლოგიკაც უფრო რთულია , მაგრამ ასევე უფრო ნელიცაა.
საბოლოოდ აქაც საუკეთესო მოდელის შემთხვევაში WOE და OHE Encoding-მა ძალიან მცირედით მაგრამ მაინც უკეთესი შედეგი მოგვცა.

ამ მიდგომების გამოყენებამდე, ჩავატარე დამატებითი feature engineering და მონაცემები შევისწავლე დღის სხვადასხვა მონაკვეთის მიხედვით TransactionDT feature-ს მეშვეობით , რამაც საინტერესო შედეგები აჩვენა , რადგან
გამოიკვეთა , რომ საათების მიხედვით დღის სხვადასხვა მონაკვეთში საგრძნობლად დიდი რაოდენობით თაღლითობა ხდებოდა . უფრო კონკრეტულად პირობითად 7-დან 10-მდე იყო საგრძნობლად დიდ რაოდენობით თაღლითობა ხდებოდა,
4-დან 7-მდე და 10-დან 14-მდე საშუალოდ , ხოლო დღის სვა მონაკვეთში მცირედ. ამიტომ ჩავთვალე კარგი იქნებოდა თუ ამ pattern-ს არ დავკარგავდი და შემოვიღე get_warning_signal ცვლადი რომელშიც ამ ინფორმაციას ვინახავდი ტრანზაქციისთვის.

ასევე leakage-ის შესამცირებლად ვიფიქრე კარგი იქნებოდა მონაცემების რაიმე ლოგიკით დაყოფა, მაგრამ რადგან ტრანზაქციის გამკეთებლის ვინაობა დაფარული იყო ჩავთვალე მათი დაყოფა გადარიცხული თანხის ოდენობების მიხედვით კარგი იქნებოდა და 
მონაცემები სამ ნაწილად: პატარა , საშუალო და დიდი რაოდენობის გადარიცხული თანხის მიხედვით დავყავი ,მაგრამ ასე დაყოფილ data-ზე მუშაობამ შედეგი გააუარესა.

/////////////Feature Selection/////////////

ამისთვის გამოვიყენე კორელაცია და PCA(რომელსაც სხვადასხვა სტატიში იყენებდნენ). აქ სგრძნობლად დიდი განსხვავება არ ყოფილა შედეგებს შორის , უბრალოდ PCA კორელაციასთან შედარებით მცირედით მეტ დროს ანდომებს კალკულაცია 
ხის მოდელებში კი ძალიან დიდი მნიშვნელობა არ აქვს ართმანეთთან კორელირებული feature-ები გვექნება თუ არა. საბოლოოდ ორივე მიდგომამ კარგად შეამცირა რიცხვითი სვეტების რაოდენობა , განსაკუთრებით v_სვეტები

/////////////Training/////////////

რავ შეეხება მოდელებს , როგორც ზემოთ ვახსენე ძირითადად გამოვიყენე tree-based მოდელები , რადგან ისინი კარგად უმკლავდებიან როგორც რიცხვით, ისე კატეგორიულ ცვლადებს და შეუძლიათ კომპლექსური არაწრფივი ნიმუშების აღმოჩენა მონაცემებში.
ისინი ასევე მდგრადები არიან კორელაციებისა და ნალების მიმართ. ხის მოდელების გარდა გამოვიყენე logistic regression-იც , რომელმაც ყველაზე ცუდი შედეგი აჩვენა მისი ROC_AUC იყო მიახლოებით 0.84 , შემდეგ მოდიოდა randomforest 0.85,
შემდეგ ADAboost 0.87 , რომელმაც ასევე ყველაზე დიდი დროც წაიღო თრაინინგისას, შემდეგ LGBMClassifier 0.91 , და ბოლოს XGBClassifier 0.91. მოდელებს ვაფასებდო ROC_AUC მიხედვით და რომელსაც უფრო მაღალი ექნებოდა ის იქნებოდა საუკეთესო 
ასეთი გამოდგა XGBClassifier. ეს ყველა მოდელი დალოგილია mlflow-ზე სადაც სხვა მეტრიკებიცა , როგორებიცაა : f1_score ,precision,recall და ა.შ. მაგრამ მათ ოპტიმიზაციაზე აღარ მიფიქრია , რადგან roc_auc მოიცავს ყველას.რაც შეეხება Hyperparameter ოპტიმიზაციას
რადგან ხის მოდელებში და დიდ მონაცემებთან დიდი დროს წაიღებდა , ვეღარ მოვახერხე.

/////////////Mlflow/////////////

პლატფორმაზე ატვირთულია თითოეული მოდელის პარამეტრები და მეტრიკები.ასევე ატვირთული მაქვს სხვადასხვა ნახაზები რამოდენიმე მოდელთან ერთად.

მოდელების ბმულები:

Logistic Regression:
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/2/runs/87545bf41975494a8408570c93906364

Randomforest:
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/0/runs/5299ec2937fe44c4bbbc958b253c3999

ADAboost:
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/0/runs/f2bf276f2f8a432496486b36b24e06ce

LGBMClassifier:
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/0/runs/b9d95d9c382b42e2bb9acba0b6efaac8
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/0/runs/1dbbb2d65773482a9b0cde6603503111
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/3/runs/a794dc8d551743bfb2d2c0a2f5a5c34b

XGBClassifier:
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/0/runs/2802a68ebe764f599d6ead0f1916ba89
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/0/runs/d1a3c7a37da240e2b54e225f7acfe573
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/0/runs/564ed5793b994481848f15e1d43f8a52
https://dagshub.com/AleksandreBakhtadze/ML-abakh22-assignment-2-IEEE-CIS-Fraud-Detection.mlflow/#/experiments/2/runs/c65b20db721e4c408638b05a02762cd2






